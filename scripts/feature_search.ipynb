{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ed2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "from itertools import combinations\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e7eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/synthetic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253c5fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98376e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataframe: pd.DataFrame, target_col: str='FL_UDSD', diagnosis_order: list=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the data by splitting into train and test sets.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input dataframe.\n",
    "        random_state (int): Random state for reproducibility.\n",
    "        target_col (str): The target column for stratification.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame]: The train and test dataframes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Clean data\n",
    "    filter_df = df[df[target_col] != 'Unknown'] # Remove rows with unknown target values\n",
    "    filter_df = filter_df[filter_df[\"MMSE\"] != -1] # Remove rows with invalid MMSE values\n",
    "    \n",
    "    # Convert columns to categorical if needed\n",
    "    filter_df['APOE'] = filter_df['APOE'].astype('category')\n",
    "    filter_df['AMYLPET'] = filter_df['AMYLPET'].astype('category')\n",
    "    \n",
    "    # Encode the target variable as an ordered categorical variable.    \n",
    "    df['FL_UDSD'] = pd.Categorical(df['FL_UDSD'], categories=diagnosis_order, ordered=True)\n",
    "    df['FL_UDSD_cat'] = df['FL_UDSD'].cat.codes \n",
    "    \n",
    "    return filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d827048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_order = ['Normal cognition', 'Subjective Cognitive Decline', 'Impaired Not SCD/MCI',\n",
    "                       'Early MCI', 'Late MCI', 'Dementia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d54697",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df = preprocess_data(dataframe = df, diagnosis_order=diagnosis_order)\n",
    "filter_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbf4db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df['FL_UDSD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2115eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df['FL_UDSD_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710d4f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(filter_df, test_size=0.2, random_state=42, stratify=filter_df['FL_UDSD_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72670ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    model,\n",
    "    target_col: str = 'FL_UDSD_cat'\n",
    ") -> dict:\n",
    "    \"\"\"Train and evaluate a single model.\"\"\"\n",
    "    X_train = train_df.drop(columns=[target_col])\n",
    "    y_train = train_df[target_col]\n",
    "    X_test = test_df.drop(columns=[target_col])\n",
    "    y_test = test_df[target_col]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "    \n",
    "    return {\n",
    "        'train_accuracy': accuracy_score(y_train, train_preds),\n",
    "        'test_accuracy': accuracy_score(y_test, test_preds),\n",
    "        'train_balanced_accuracy': balanced_accuracy_score(y_train, train_preds),\n",
    "        'test_balanced_accuracy': balanced_accuracy_score(y_test, test_preds),\n",
    "        'train_f1_score': f1_score(y_train, train_preds, average='macro'),\n",
    "        'test_f1_score': f1_score(y_test, test_preds, average='macro')\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec8b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage: call it multiple times\n",
    "rf_results = train_and_evaluate_model(train_df, test_df, RandomForestClassifier(random_state=42))\n",
    "lr_results = train_and_evaluate_model(train_df, test_df, LogisticRegression(max_iter=1000, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e3707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def comprehensive_feature_search(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    target_col: str = 'FL_UDSD_cat',\n",
    "    min_features: int = 2,\n",
    "    max_features: int = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Test all possible feature subsets with multiple models.\n",
    "    \n",
    "    Args:\n",
    "        train_df: Training dataframe\n",
    "        test_df: Test dataframe\n",
    "        target_col: Name of target column to exclude from features\n",
    "        min_features: Minimum number of features in a subset (default: 2)\n",
    "        max_features: Maximum number of features in a subset (default: all features)\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Results sorted by test balanced accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all available features (excluding target column)\n",
    "    all_features = [col for col in train_df.columns if col != target_col]\n",
    "    \n",
    "    if max_features is None:\n",
    "        max_features = len(all_features)\n",
    "    \n",
    "    print(f\"Total features available: {len(all_features)}\")\n",
    "    print(f\"Features: {all_features}\\n\")\n",
    "    \n",
    "    # Define models to test\n",
    "    models = {\n",
    "        'RandomForest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "        'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Try all subset sizes from min_features to max_features\n",
    "    for n_features in range(min_features, max_features + 1):\n",
    "        # Generate all combinations of n_features\n",
    "        feature_combinations = list(combinations(all_features, n_features))\n",
    "        \n",
    "        print(f\"Testing {len(feature_combinations)} combinations with {n_features} features...\")\n",
    "        \n",
    "        # Test each combination with each model\n",
    "        for features in tqdm(feature_combinations, desc=f\"{n_features} features\"):\n",
    "            features = list(features)\n",
    "            \n",
    "            # Prepare data with selected features\n",
    "            X_train = train_df[features]\n",
    "            y_train = train_df[target_col]\n",
    "            X_test = test_df[features]\n",
    "            y_test = test_df[target_col]\n",
    "            \n",
    "            # Test each model\n",
    "            for model_name, model in models.items():\n",
    "                try:\n",
    "                    # Train model\n",
    "                    model.fit(X_train, y_train)\n",
    "                    \n",
    "                    # Make predictions\n",
    "                    train_preds = model.predict(X_train)\n",
    "                    test_preds = model.predict(X_test)\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    result = {\n",
    "                        'model': model_name,\n",
    "                        'n_features': n_features,\n",
    "                        'features': ', '.join(features),\n",
    "                        'train_accuracy': accuracy_score(y_train, train_preds),\n",
    "                        'test_accuracy': accuracy_score(y_test, test_preds),\n",
    "                        'train_balanced_acc': balanced_accuracy_score(y_train, train_preds),\n",
    "                        'test_balanced_acc': balanced_accuracy_score(y_test, test_preds),\n",
    "                        'train_f1': f1_score(y_train, train_preds, average='macro'),\n",
    "                        'test_f1': f1_score(y_test, test_preds, average='macro')\n",
    "                    }\n",
    "                    \n",
    "                    results.append(result)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # Skip combinations that cause errors\n",
    "                    print(f\"Error with {model_name} and features {features}: {e}\")\n",
    "                    continue\n",
    "    \n",
    "    # Convert to DataFrame and sort by test balanced accuracy\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('test_balanced_acc', ascending=False)\n",
    "    \n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33129307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the comprehensive search\n",
    "print(\"Starting comprehensive feature search...\\n\")\n",
    "results_df = comprehensive_feature_search(\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    target_col='FL_UDSD_cat',\n",
    "    min_features=2,\n",
    "    max_features=10  # Use all features or set a limit like 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c556597d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
